{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNPf0i-FJmq3",
        "outputId": "fa848cae-7843-449f-ffd5-14dd2b60dc0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.55.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n"
          ]
        }
      ],
      "source": [
        "# Install package to enable importing environment variables for secret keys (e.g. API key)\n",
        "!pip install python-dotenv\n",
        "# Imports for RAG & Vector DB\n",
        "!pip install faiss-cpu sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V7EBV_QFP0dP"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "# Import variables from .env\n",
        "api_key = os.getenv('API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Eu1LXJbwc9Oc"
      },
      "outputs": [],
      "source": [
        "# access the specific OpenAI project\n",
        "client = OpenAI(api_key=api_key,project=os.getenv('PROJECT_ID'))\n",
        "# specify vector store id\n",
        "vec_id = os.getenv('VEC_ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8-heWHwHTcXD"
      },
      "outputs": [],
      "source": [
        "def upload_pdf(filepath: str) -> None:\n",
        "  # open the pdf file and create an object which could be interpreted by openai\n",
        "  with open(filepath, \"rb\") as file_obj:\n",
        "      f = client.files.create(file=file_obj, purpose=\"assistants\")\n",
        "      # push pdf to vector store\n",
        "      client.vector_stores.files.create(\n",
        "          vector_store_id=vec_id,\n",
        "          file_id=f.id,\n",
        "      )\n",
        "  print(\"Uploaded \" + filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9GX8OXmVWZO",
        "outputId": "2ba2fa30-42b1-48ec-dba3-4cc4bcaf5c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded data/Introduction to Support Vector Machines.pdf\n",
            "Uploaded data/Introduction to Neural Networks.pdf\n",
            "Uploaded data/(Re)-Introduction to Data Science & Control Flow.pptx.pdf\n",
            "Uploaded data/Advanced Abstraction.pptx.pdf\n",
            "Uploaded data/Advanced Control Flow.pptx.pdf\n",
            "Uploaded data/Bayes Theorem Review.pdf\n",
            "Uploaded data/Measures of Dispersion & Central Limit Theorem.pdf\n",
            "Uploaded data/Random Forests.pdf\n",
            "Uploaded data/Introduction to Data Processing.pptx.pdf\n",
            "Uploaded data/Introduction to the Naive Bayes Classifier.pdf\n",
            "Uploaded data/Introduction to Decision Trees.pdf\n",
            "Uploaded data/Transformer Architecture.pdf\n",
            "Uploaded data/NLP & Vector Embeddings.pdf\n",
            "Uploaded data/Introduction to Unsupervised Learning Algorithms.pdf\n",
            "Uploaded data/Applied LLMs & Agents.pdf\n",
            "Uploaded data/Dimensionality Reduction with PCA.pdf\n",
            "Uploaded data/Introduction to K-Nearest-Neighbors.pdf\n",
            "Uploaded data/Feature Engineering and Wrangling.pdf\n"
          ]
        }
      ],
      "source": [
        "slides_dir = '../data/'\n",
        "folder = os.listdir(slides_dir)\n",
        "# upload each pdf to vector DB\n",
        "for f in folder:\n",
        "    path = slides_dir + f\n",
        "    if os.path.isfile(path):\n",
        "        upload_pdf(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "AoAv7OVIzW4w"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "# Identity\n",
        "\n",
        "You are a Lecture Navigator program that points the user to the Data Science & Machine Learning lecture slides containing information relevant to the user prompt.\n",
        "\n",
        "# Instructions\n",
        "\n",
        "* The answer should only contain the slides file name and page numbers.\n",
        "\n",
        "* If only one slide file contains relevant information, output in the format below.\n",
        "+ Slides: <slide_filename>\n",
        "  Pages: <page_numbers_list>\n",
        "  Explanation:\n",
        "\n",
        "* If more than one slide file contains relevant information, create a repeated response for the additional findings in the format above.\n",
        "For example, if there are 2 files containing relevant information, the output should look like the following.\n",
        "+ Slides: <slide_filename>\n",
        " Pages: <page_numbers_list>\n",
        " Explanation:\n",
        "\n",
        "+ Slides: <slide_filename>\n",
        "  Pages: <page_numbers_list>\n",
        "  Explanation:\n",
        "\n",
        "If there are 3 files containing relevant information, the output should look like the following.\n",
        "+ Slides: <slide_filename>\n",
        "  Pages: <page_numbers_list>\n",
        "  Explanation:\n",
        "\n",
        "+ Slides: <slide_filename>\n",
        "  Pages: <page_numbers_list>\n",
        "  Explanation:\n",
        "\n",
        "+ Slides: <slide_filename>\n",
        "  Pages: <page_numbers_list>\n",
        "  Explanation:\n",
        "\n",
        "* Numbers in <page_numbers_list> should be displayed in ascending order.\n",
        "\n",
        "* If <page_numbers_list> contains continuous numbers, shorten them into number ranges. For example, `1, 2, 3, 4, 14, 15, 16, 17` will be `1-4, 14-17`\n",
        "\n",
        "* If the prompt is irrelevant to Data Science & Machine Learning or no relevant slides can be found, simply out `No relevant slides found.`\n",
        "\n",
        "# Examples\n",
        "\n",
        "<user_query>\n",
        "Which lecture slides mentioned Euclidean Distance?\n",
        "</user_query>\n",
        "\n",
        "<assistant_response>\n",
        "+ Slides: Introduction to K-Nearest-Neighbors\n",
        " Pages: 23, 25-31, 73\n",
        "</assistant_response>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OCzOJFJNSANX"
      },
      "outputs": [],
      "source": [
        "def ask(prompt: str) -> str:\n",
        "    resp = client.responses.create(\n",
        "      model='gpt-4o-mini',\n",
        "      instructions=system_prompt,\n",
        "      input=prompt,\n",
        "      tools=[{\"type\": \"file_search\", \"vector_store_ids\": [vec_id]}],\n",
        "    )\n",
        "    return resp.output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS9ZFRVDVbJh",
        "outputId": "9955f3e6-4282-4475-a1e3-d240b115854e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+ Slides: Introduction to Unsupervised Learning Algorithms.pdf\n",
            "  Pages: 1, 2, 4, 9\n",
            "  Explanation: Discusses the use of squared Euclidean distance in calculating cluster variance and centroid assignment.\n",
            "\n",
            "+ Slides: Introduction to Support Vector Machines.pdf\n",
            "  Pages: 3, 4, 5\n",
            "  Explanation: Explains the distance from a support vector to the hyperplane using a form akin to the Euclidean distance.\n",
            "\n",
            "+ Slides: Introduction to K-Nearest-Neighbors.pdf\n",
            "  Pages: 7, 12, 17\n",
            "  Explanation: Details the calculation of Euclidean distance in kNN and its importance in measuring distances between data points.\n"
          ]
        }
      ],
      "source": [
        "print(ask(\"Which lecture slides mentioned Euclidean Distance?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R4yPGwumtLb",
        "outputId": "7fba7c15-d010-491f-d766-9955ea839ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+ Slides: Introduction to K-Nearest-Neighbors.pdf\n",
            "  Pages: 1, 3-4, 11-12, 17-19\n",
            "  Explanation: These pages provide a detailed explanation of Euclidean distance, including its mathematical background using Pythagorean theorem and its application in measuring distance between points in multiple dimensions.\n",
            "\n",
            "+ Slides: Introduction to Unsupervised Learning Algorithms.pdf\n",
            "  Pages: 4-5\n",
            "  Explanation: Discusses the use of squared Euclidean distance in the context of clustering algorithms, specifically K-Means, and how it relates to variance calculations within clusters.\n"
          ]
        }
      ],
      "source": [
        "print(ask(\"What is Euclidean Distance?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XD-3ddzyuvab"
      },
      "outputs": [],
      "source": [
        "test_prompts = [\n",
        "    \"During phase one we learned about variance, how is it related to standard deviation\",\n",
        "    \"How do you import a CSV file?\",\n",
        "    \"What is the difference between Lasso and Ridge?\",\n",
        "    \"What day did we learn about elbow, gap and silhouette?\",\n",
        "    \"Is K-means the same thing as KNN?\",\n",
        "    \"How much is the TKH monthly stipend?\",\n",
        "    \"What is the difference between a print statement and a return statement?\",\n",
        "    \"How can I combine 2 tables together in SQL?\"\n",
        "    \"Can you show me the slide that explains supervised learning?\",\n",
        "    \"Which module covers supervised learning?\",\n",
        "    \"I need the part about labeled data training\",\n",
        "    \"What kind of EDA uses a bar graph?\",\n",
        "    \"What is the difference between structured data and unstructured data?\",\n",
        "    \"A tuple is immutable, right?\"\n",
        "    \"What date did we learn about Explanation of Data Analaysis aka EDA?\"\n",
        "    \"Where's the slide that covers wbe scraping use API keys?\",\n",
        "    \"After I create my repository on Github I can just hit git push, correct?\",\n",
        "    \"What are the steps for pushing code to Github?\",\n",
        "    \"How much did Elon Musk donate to TKH last year?\",\n",
        "    \"What is the difference between one-hot encoding and dummy encoding?\",\n",
        "    \"Compare decision trees vs random forests.\",\n",
        "    \"What kind of graph uses red dots?\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPBrvU3suvYg",
        "outputId": "3885d27a-449e-4468-eb57-53904f50a14f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q1. During phase one we learned about variance, how is it related to standard deviation\n",
            "   + Slides: Measures of Dispersion & Central Limit Theorem.pdf\n",
            "  Pages: 6-8, 14\n",
            "  Explanation: These pages explain the mathematical relationship between variance and standard deviation, detailing how standard deviation is the square root of variance, thus connecting the two concepts directly.\n",
            "---------------------------------------------------------------------------\n",
            "Q2. How do you import a CSV file?\n",
            "   + Slides: Introduction to Data Analytics II (1).pdf\n",
            "  Pages: 0, 1, 2\n",
            "  Explanation: This section provides detailed instructions on how to import a CSV file using the pandas library in Python, demonstrating the `pd.read_csv()` method.\n",
            "---------------------------------------------------------------------------\n",
            "Q3. What is the difference between Lasso and Ridge?\n",
            "   + Slides: Introduction to Neural Networks.pdf\n",
            "  Pages: 3, 11, 22\n",
            "  Explanation: This section discusses Lasso and Ridge regression, detailing their key differences, including regularization methods and their impact on model performance.\n",
            "\n",
            "+ Slides: Feature Engineering and Wrangling.pdf\n",
            "  Pages: 5, 10\n",
            "  Explanation: This content covers aspects of Lasso and Ridge within the context of feature selection and model complexity management.\n",
            "---------------------------------------------------------------------------\n",
            "Q4. What day did we learn about elbow, gap and silhouette?\n",
            "   + Slides: Introduction to Unsupervised Learning Algorithms.pdf\n",
            "  Pages: 0, 1-4\n",
            "  Explanation: The slides discuss the elbow method, average silhouette, and gap statistic as techniques for finding optimal clusters in unsupervised learning.\n",
            "---------------------------------------------------------------------------\n",
            "Q5. Is K-means the same thing as KNN?\n",
            "   + Slides: Introduction to Unsupervised Learning Algorithms\n",
            "  Pages: 10, 11\n",
            "  Explanation: The slides clarify that K-means and KNN (K-Nearest Neighbors) are different algorithms. K-means is an unsupervised clustering method, while KNN is a supervised classification method, exploiting different principles within machine learning.\n",
            "\n",
            "+ Slides: Introduction to K-Nearest-Neighbors\n",
            "  Pages: 10, 15\n",
            "  Explanation: These slides discuss KNN in detail, describing it as a supervised learning algorithm that classifies data points based on their nearest labeled neighbors, highlighting the fundamental differences from K-means.\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Ask each question in the test prompts\n",
        "for i in range(0,5):\n",
        "    print(\"Q\" + str(i+1) + \". \" + test_prompts[i])\n",
        "    print(\"   \" + ask(test_prompts[i]))\n",
        "    print(\"---------------------------------------------------------------------------\")\n",
        "    # delay for 2 seconds before sending the next prompt\n",
        "    time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1avBYcoo4rp",
        "outputId": "26d8cc6e-7e4f-4543-fc76-8714121a04d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q6. How much is the TKH monthly stipend?\n",
            "   No relevant slides found.\n",
            "---------------------------------------------------------------------------\n",
            "Q7. What is the difference between a print statement and a return statement?\n",
            "   No relevant slides found.\n",
            "---------------------------------------------------------------------------\n",
            "Q8. How can I combine 2 tables together in SQL?Can you show me the slide that explains supervised learning?\n",
            "   + Slides: Introduction to Structured Databases I.pdf\n",
            "  Pages: 0-1, 5-6, 11-12\n",
            "  Explanation: This section explains how to combine tables using SQL JOINs, including various types of joins like Inner Join, Left Join, Right Join, and Full Join.\n",
            "\n",
            "+ Slides: Introduction to Decision Trees.pdf\n",
            "  Pages: 15\n",
            "  Explanation: This slide provides an overview of supervised learning, emphasizing how predictions are made based on input features and their relationships to target outcomes.\n",
            "---------------------------------------------------------------------------\n",
            "Q9. Which module covers supervised learning?\n",
            "   + Slides: Introduction to Support Vector Machines.pdf\n",
            "  Pages: 4, 5, 8\n",
            "  Explanation: Covers the fundamentals of supervised learning classifiers, specifically focusing on Support Vector Machines (SVM).\n",
            "\n",
            "+ Slides: Introduction to Decision Trees.pdf\n",
            "  Pages: 8, 10-12, 14\n",
            "  Explanation: Discusses decision trees as a non-parametric multiclass supervised learning algorithm, including definitions and applications.\n",
            "\n",
            "+ Slides: Bayes Theorem Review.pdf\n",
            "  Pages: 6-7, 9-10\n",
            "  Explanation: Describes supervised learning methods and classification tasks, including logistic regression and Naive Bayes classifiers.\n",
            "\n",
            "+ Slides: Random Forests.pdf\n",
            "  Pages: 12-13\n",
            "  Explanation: Introduces Random Forest as a supervised learning tool and discusses its features and considerations.\n",
            "---------------------------------------------------------------------------\n",
            "Q10. I need the part about labeled data training\n",
            "   + Slides: Introduction to Supervised Learning Algorithms\n",
            "  Pages: 10, 12-13, 18\n",
            "  Explanation: This section discusses labeled data training as a crucial aspect of supervised learning, emphasizing the distinction between labeled and unlabeled data.\n",
            "\n",
            "+ Slides: Introduction to K-Nearest-Neighbors\n",
            "  Pages: 15-16, 20-21\n",
            "  Explanation: These pages explain how KNN utilizes labeled data during the training process to create decision boundaries for classification.\n",
            "\n",
            "+ Slides: Introduction to Support Vector Machines\n",
            "  Pages: 2-3, 5-7\n",
            "  Explanation: This part outlines how SVMs rely on labeled data to optimize the decision boundary separating classes in a dataset .\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(5,10):\n",
        "    print(\"Q\" + str(i+1) + \". \" + test_prompts[i])\n",
        "    print(\"   \" + ask(test_prompts[i]))\n",
        "    print(\"---------------------------------------------------------------------------\")\n",
        "    # delay for 2 seconds before sending the next prompt\n",
        "    time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En21xBZ1pB0h",
        "outputId": "b7d14c53-6cb7-45cf-9e9d-63a6cd3cd7b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q11. What kind of EDA uses a bar graph?\n",
            "   + Slides: Measures of Dispersion & Central Limit Theorem.pdf\n",
            "  Pages: 10, 12\n",
            "  Explanation: The slides discuss the use of bar charts in exploratory data analysis (EDA) to represent discrete data and showcase successes in relation to events.\n",
            "\n",
            "+ Slides: Feature Engineering and Wrangling.pdf\n",
            "  Pages: 7, 8\n",
            "  Explanation: These slides highlight the significance of visualizing data types and transformations, including the application of bar graphs in EDA.\n",
            "---------------------------------------------------------------------------\n",
            "Q12. What is the difference between structured data and unstructured data?\n",
            "   + Slides: NLP & Vector Embeddings.pdf\n",
            "  Pages: 1, 2, 4\n",
            "  Explanation: The slides discuss structured and unstructured data, explaining that approximately 80% of enterprise data is unstructured, and providing examples of various forms of unstructured data.\n",
            "\n",
            "+ Slides: Feature Engineering and Wrangling.pdf\n",
            "  Pages: 4, 5, 19\n",
            "  Explanation: These slides cover data cleaning and wrangling processes, emphasizing the importance of structured data in machine learning and data analysis.\n",
            "---------------------------------------------------------------------------\n",
            "Q13. A tuple is immutable, right?What date did we learn about Explanation of Data Analaysis aka EDA?Where's the slide that covers wbe scraping use API keys?\n",
            "   + Slides: Advanced Python Refresher.pptx\n",
            "  Pages: 11, 12, 14-16\n",
            "  Explanation: These pages cover web scraping and the use of API keys, discussing how to request data from websites and APIs.\n",
            "\n",
            "+ Slides: (Re)-Introduction to Data Science & Control Flow.pptx\n",
            "  Pages: 1, 2\n",
            "  Explanation: These pages mention key dates and assignments, including the checkpoint related to Explanation of Data Analysis (EDA) due on 7/16.\n",
            "---------------------------------------------------------------------------\n",
            "Q14. After I create my repository on Github I can just hit git push, correct?\n",
            "   No relevant slides found.\n",
            "---------------------------------------------------------------------------\n",
            "Q15. What are the steps for pushing code to Github?\n",
            "   No relevant slides found.\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(10,15):\n",
        "    print(\"Q\" + str(i+1) + \". \" + test_prompts[i])\n",
        "    print(\"   \" + ask(test_prompts[i]))\n",
        "    print(\"---------------------------------------------------------------------------\")\n",
        "    # delay for 2 seconds before sending the next prompt\n",
        "    time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9zkW5ETpGUy",
        "outputId": "ef6ed752-6e08-4dd3-83dc-70c5ac4a81fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q16. How much did Elon Musk donate to TKH last year?\n",
            "   No relevant slides found.\n",
            "---------------------------------------------------------------------------\n",
            "Q17. What is the difference between one-hot encoding and dummy encoding?\n",
            "   + Slides: Feature Engineering and Wrangling.pdf\n",
            "  Pages: 0, 1\n",
            "  Explanation: The slides explain the differences between One-Hot Encoding and Dummy Encoding, highlighting that Dummy Encoding leaves one variable out to avoid multicollinearity issues when categories are closely related.\n",
            "---------------------------------------------------------------------------\n",
            "Q18. Compare decision trees vs random forests.\n",
            "   + Slides: Random Forests.pdf  \n",
            "  Pages: 1-2, 8-10, 12-13, 18  \n",
            "  Explanation: These pages compare random forests and decision trees, detailing how random forests enhance decision trees by introducing bootstrapping and feature selection, leading to improved accuracy and reduced overfitting.\n",
            "\n",
            "+ Slides: Introduction to Decision Trees.pdf  \n",
            "  Pages: 1-3, 5-6, 16  \n",
            "  Explanation: These slides explain the fundamentals of decision trees, including their structure, functioning, and inherent drawbacks such as tendency to overfit without appropriate regularization or ensemble techniques.\n",
            "---------------------------------------------------------------------------\n",
            "Q19. What kind of graph uses red dots?\n",
            "   + Slides: Introduction to K-Nearest-Neighbors.pdf\n",
            "  Pages: 0, 1, 3, 5\n",
            "  Explanation: The slides reference \"Red = cat; yellow = hammie; blue = dog\" in the context of visualizing classification using red dots for cats in a scatter plot.\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(15,len(test_prompts)):\n",
        "    print(\"Q\" + str(i+1) + \". \" + test_prompts[i])\n",
        "    print(\"   \" + ask(test_prompts[i]))\n",
        "    print(\"---------------------------------------------------------------------------\")\n",
        "    # delay for 2 seconds before sending the next prompt\n",
        "    time.sleep(2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ds",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
